{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graphs with Neo4j\n",
    "- ref: https://neo4j.com/labs/genai-ecosystem/llamaindex/\n",
    "- ref: https://docs.llamaindex.ai/en/latest/module_guides/indexing/lpg_index_guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.litellm import LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.llms.litellm import LiteLLM\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.litellm import LiteLLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from google.genai.types import EmbedContentConfig\n",
    "from core.custom_components.custom_parsers import CustomMarkdownNodeParser\n",
    "from core.custom_components.custom_google_genai import CustomGoogleGenAI\n",
    "from core.utilities import GoogleGenAIDummyTokensizer\n",
    "# pip install graspologic\n",
    "from llama_index.core import Settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# llm = CustomGoogleGenAI(\n",
    "#             model=\"gemini-2.5-flash\", #\"gemini-2.0-flash\",\n",
    "#             api_key=os.environ['GEMINI_API_KEY'], \n",
    "#             max_retries=2,  # Number of retry attempts\n",
    "#             retry_on_rate_limit=True,\n",
    "#             additional_kwargs={\"stream_options\": {\"include_usage\": True}}\n",
    "#         )\n",
    "# llm = OpenAI(model=\"gemini-2.0-flash\",\n",
    "#             api_key=os.environ['GEMINI_API_KEY'],\n",
    "#             api_base=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "#             max_retries=2,  # Number of retry attempts\n",
    "#             retry_on_rate_limit=True,\n",
    "#             additional_kwargs={\"stream_options\": {\"include_usage\": True}})\n",
    "# from llama_index.llms.ollama import Ollama\n",
    "# llm = Ollama(model=\"gemma3:12b\", request_timeout=120.0, context_window=8000)\n",
    "\n",
    "llm = LiteLLM(model=\"gemini/gemini-2.5-flash\", max_tokens=8192, max_retries=6)\n",
    "Settings.llm = llm\n",
    "\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "embed_model = GoogleGenAIEmbedding(model_name=\"models/text-embedding-004\", api_key=os.environ['GEMINI_API_KEY'])\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "\n",
    "# use the tiktoken (set by default) only, since some types of input only supported by tiktoken only.\n",
    "# tokenizer = GoogleGenAIDummyTokensizer(llm).encode\n",
    "# import tiktoken\n",
    "# tokenizer = tiktoken.encoding_for_model('gpt-4o').encode\n",
    "# Settings.tokenizer = tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "INPUT_DIR = '../data/langchain/docs/docs'\n",
    "FILE_TYPES = ['.md', '.mdx']\n",
    "\n",
    "documents = SimpleDirectoryReader(input_dir=INPUT_DIR, exclude=[], recursive=True, filename_as_id=True,\n",
    "                                       required_exts=FILE_TYPES).load_data()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\rag.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\retrieval.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\retrievers.mdx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_start, doc_end = 25, 28\n",
    "\n",
    "for doc in documents[doc_start:doc_end]:\n",
    "    print(doc.id_)\n",
    "# Concatenate documents with filename and content\n",
    "# concatenated_docs = \"\"\n",
    "# for doc in documents[doc_start:doc_end]:\n",
    "#     file_path = doc.metadata['file_path']\n",
    "#     path_parts = file_path.split('\\\\')\n",
    "#     file_name = '\\\\'.join(path_parts[-2:])\n",
    "#     concatenated_docs += f\"\\n\\n=== File: {file_name} ===\\n\\n\"\n",
    "#     concatenated_docs += doc.text\n",
    "#     concatenated_docs += \"\\n\\n=== End File ===\\n\"\n",
    "# print(concatenated_docs)\n",
    "\n",
    "# len(concatenated_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "md_node_parser = CustomMarkdownNodeParser(max_tokens=2000, max_header_level=2, tokenizer=Settings.tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_nodes = md_node_parser.get_nodes_from_documents(documents[doc_start:doc_end])\n",
    "len(md_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 10\n",
    "# total_batches = math.ceil(len(nodes) / batch_size)\n",
    "# for batch_idx in range(total_batches):\n",
    "    #     start_idx = batch_idx * batch_size\n",
    "    # end_idx = min(start_idx + batch_size, len(md_nodes)) \n",
    "    # batch_nodes = md_nodes[start_idx:end_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Sure Neo4j Desktop (or cli) is started and database is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"pineapple\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    database=\"doc2agent\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor, DynamicLLMPathExtractor\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gindex = PropertyGraphIndex(\n",
    "    nodes=[],\n",
    "    llm=llm,\n",
    "    embed_model=embed_model, \n",
    "    property_graph_store=graph_store, \n",
    "    \n",
    "    kg_extractors=[\n",
    "        DynamicLLMPathExtractor(\n",
    "        llm=llm\n",
    "    )],\n",
    "    use_async=True,\n",
    "    show_progress=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langfuse client is authenticated and ready!\n"
     ]
    }
   ],
   "source": [
    "# setup observability\n",
    "from langfuse import get_client\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "\n",
    "langfuse = get_client()\n",
    " \n",
    "# Verify connection\n",
    "langfuse_available = False\n",
    "if langfuse.auth_check():\n",
    "    langfuse_available = True\n",
    "    LlamaIndexInstrumentor().instrument()\n",
    "    print(\"Langfuse client is authenticated and ready!\")\n",
    "else:\n",
    "    print(\"Authentication failed. Please check your credentials and host.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting and inferring knowledge graph from text: 100%|██████████| 30/30 [02:49<00:00,  5.66s/it]\n",
      "Trace ID is not set. Creating generation client with new trace id.\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "Trace ID is not set. Creating generation client with new trace id.\n",
      "Generating embeddings: 100%|██████████| 38/38 [00:02<00:00, 16.54it/s]\n",
      "Trace ID is not set. Creating generation client with new trace id.\n"
     ]
    }
   ],
   "source": [
    "# insert nodes: It takes care of existing nodes and relationships. Not an issue if it is run multiple times.\n",
    "if not langfuse_available:\n",
    "    gindex.insert_nodes(md_nodes)\n",
    "else:\n",
    "    with langfuse.start_as_current_span(name=\"Building graph index\"):\n",
    "        gindex.insert_nodes(md_nodes)\n",
    "    langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check hash of nodes (llama nodes, not kg node)\n",
    "# from hashlib import sha256\n",
    "\n",
    "# node = md_nodes[0]\n",
    "# doc_identity = str(node.text) + str(node.metadata)\n",
    "# print(node.hash)\n",
    "# print(str(sha256(doc_identity.encode(\"utf-8\", \"surrogatepass\")).hexdigest()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docinfo = gindex.docstore.get_all_ref_doc_info()\n",
    "docstore_nodes = gindex.docstore.get_nodes(node_ids=[n.id_ for n in md_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docinfo), len(docstore_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get triplets\n",
    "trips = gindex.property_graph_store.get_triplets()\n",
    "len(trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntityNode(label='AI_MODEL', embedding=None, properties={'header_path': '/', 'id': 'language models', 'creation_date': '2025-02-21', 'last_modified_date': '2025-02-21', 'file_size': 1695, 'file_path': 'h:\\\\Coding\\\\ml\\\\llm\\\\agents\\\\documentation_agent\\\\graph_rag\\\\..\\\\data\\\\langchain\\\\docs\\\\docs\\\\concepts\\\\agents.mdx', 'file_name': 'agents.mdx', 'triplet_source_id': 'ccf913ef-c17b-4f7d-9f51-876277bb10cc'}, name='language models'),\n",
       " Relation(label='CANNOT', source_id='language models', target_id='take actions', properties={'header_path': '/', 'creation_date': '2025-02-21', 'last_modified_date': '2025-02-21', 'file_size': 1695, 'file_path': 'h:\\\\Coding\\\\ml\\\\llm\\\\agents\\\\documentation_agent\\\\graph_rag\\\\..\\\\data\\\\langchain\\\\docs\\\\docs\\\\concepts\\\\agents.mdx', 'file_name': 'agents.mdx', 'triplet_source_id': 'ccf913ef-c17b-4f7d-9f51-876277bb10cc'}),\n",
       " EntityNode(label='ACTION', embedding=None, properties={'header_path': '/', 'id': 'take actions', 'creation_date': '2025-02-21', 'last_modified_date': '2025-02-21', 'file_size': 1695, 'file_path': 'h:\\\\Coding\\\\ml\\\\llm\\\\agents\\\\documentation_agent\\\\graph_rag\\\\..\\\\data\\\\langchain\\\\docs\\\\docs\\\\concepts\\\\agents.mdx', 'file_name': 'agents.mdx', 'triplet_source_id': 'ccf913ef-c17b-4f7d-9f51-876277bb10cc'}, name='take actions')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='ccf913ef-c17b-4f7d-9f51-876277bb10cc', embedding=None, metadata={'file_path': 'h:\\\\Coding\\\\ml\\\\llm\\\\agents\\\\documentation_agent\\\\graph_rag\\\\..\\\\data\\\\langchain\\\\docs\\\\docs\\\\concepts\\\\agents.mdx', 'file_name': 'agents.mdx', 'file_size': 1695, 'creation_date': '2025-02-21', 'last_modified_date': '2025-02-21', 'header_path': '/'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='h:\\\\Coding\\\\ml\\\\llm\\\\agents\\\\documentation_agent\\\\graph_rag\\\\..\\\\data\\\\langchain\\\\docs\\\\docs\\\\concepts\\\\agents.mdx', node_type='4', metadata={'file_path': 'h:\\\\Coding\\\\ml\\\\llm\\\\agents\\\\documentation_agent\\\\graph_rag\\\\..\\\\data\\\\langchain\\\\docs\\\\docs\\\\concepts\\\\agents.mdx', 'file_name': 'agents.mdx', 'file_size': 1695, 'creation_date': '2025-02-21', 'last_modified_date': '2025-02-21'}, hash='8576f8cfa3bf7b8c181b90265c552b2b2eb4949d5df63045b7c6855e6950eb04'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='705e1777-8580-4ee2-9fce-d6ce6d0eb95a', node_type='1', metadata={'header_path': '/Agents/'}, hash='ff074b3e5ec0ea762cdb9dc901f750a09eae188fd7adc81ec8f28def14108401')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"# Agents\\n\\nBy themselves, language models can't take actions - they just output text. Agents are systems that take a high-level task and use an LLM as a reasoning engine to decide what actions to take and execute those actions.\\n\\n[LangGraph](/docs/concepts/architecture#langgraph) is an extension of LangChain specifically aimed at creating highly controllable and customizable agents. We recommend that you use LangGraph for building agents.\\n\\nPlease see the following resources for more information:\\n\\n* LangGraph docs on [common agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\\n* [Pre-built agents in LangGraph](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)\", mimetype='text/plain', start_char_idx=0, end_char_idx=771, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln = gindex.property_graph_store.get_llama_nodes(node_ids=['ccf913ef-c17b-4f7d-9f51-876277bb10cc'])\n",
    "ln[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1329"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knowledge Graph Nodes\n",
    "kgn = gindex.property_graph_store.get()\n",
    "len(kgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"+ operator ({'header_path': '/Messages/LangChain Messages/AIMessageChunk/', 'creation_date': '2025-02-21', 'last_modified_date': '2025-02-21', 'file_size': 15252, 'file_path': 'h:\\\\\\\\Coding\\\\\\\\ml\\\\\\\\llm\\\\\\\\agents\\\\\\\\documentation_agent\\\\\\\\graph_rag\\\\\\\\..\\\\\\\\data\\\\\\\\langchain\\\\\\\\docs\\\\\\\\docs\\\\\\\\concepts\\\\\\\\messages.mdx', 'name': '+ operator', 'file_name': 'messages.mdx', 'triplet_source_id': '7c3a0e08-7b05-4c88-b4fd-d28920f23926'})\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(kgn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 200, 692)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph schema\n",
    "graph_schema = gindex.property_graph_store.get_schema()\n",
    "len(graph_schema['node_props']), len(graph_schema['rel_props']), len(graph_schema['relationships'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['node_props', 'rel_props', 'relationships', 'metadata'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gindex.property_graph_store.get_schema().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Retreival and Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\agents.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\architecture.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\async.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\callbacks.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\chat_history.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\chat_models.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\document_loaders.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\embedding_models.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\evaluation.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\example_selectors.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\few_shot_prompting.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\index.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\key_value_stores.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\lcel.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\messages.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\multimodality.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\output_parsers.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\prompt_templates.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\rag.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\retrieval.mdx\n",
      "h:\\Coding\\ml\\llm\\agents\\documentation_agent\\notebooks\\..\\data\\langchain\\docs\\docs\\concepts\\retrievers.mdx\n"
     ]
    }
   ],
   "source": [
    "for doc in documents[7:28]:\n",
    "    print(doc.id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35805.25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate documents with filename and content\n",
    "concatenated_docs = \"\"\n",
    "for doc in documents[7:28]:\n",
    "    file_path = doc.metadata['file_path']\n",
    "    path_parts = file_path.split('\\\\')\n",
    "    file_name = '\\\\'.join(path_parts[-2:])\n",
    "    concatenated_docs += f\"\\n\\n=== File: {file_name} ===\\n\\n\"\n",
    "    concatenated_docs += doc.text\n",
    "    concatenated_docs += \"\\n\\n=== End File ===\\n\"\n",
    "len(concatenated_docs) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"what are the functions in BaseStores in langchain?\",\n",
    "    \"what are the different types of retreivers supported by langchain?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define retriever\n",
    "retriever = gindex.as_retriever(\n",
    "    include_text=True,  # include source text in returned nodes, default True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not langfuse_available:\n",
    "    results = retriever.retrieve(queries[1])\n",
    "else:\n",
    "    with langfuse.start_as_current_span(name=\"retieve graph index\"):\n",
    "        results = retriever.retrieve(queries[1])\n",
    "    langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Retrieval -> REQUIRES -> Retrievers\n",
      "\n",
      "## Information retrieval\n",
      "****************************************************************************************************\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Retrievers -> TYPE_OF -> Common types\n",
      "Retrievers -> RETURN -> list of Document objects\n",
      "Retrievers -> DO_NOT_NEED_TO -> store documents\n",
      "Retrievers -> CAN_BE_BUILT_ON -> search APIs\n",
      "Retrievers -> BUILT_ON -> graph databases\n",
      "Retrievers -> BUILT_ON -> relational database\n",
      "Retrievers -> UTILIZE -> index\n",
      "\n",
      "### Source document retention \n",
      "\n",
      "Many retrievers utilize some kind of index to make documents easily searchable.\n",
      "The process of indexing can include a transformation step (e.g., vectorstores often use document splitting). \n",
      "Whatever transformation is used, can be very useful to retain a link between the *transformed document* and the original, giving the retriever the ability to return the *original* document.\n",
      "\n",
      "![Retrieval with full docs](/img/retriever_full_docs.png)\n",
      "\n",
      "This is particularly useful in AI applications, because it ensures no loss in document context for the model.\n",
      "For example, you may use small chunk size for indexing documents in a vectorstore. \n",
      "If you return *only* the chunks as the retrieval result, then the model will have lost the original document context for the chunks. \n",
      "\n",
      "LangChain has two different retrievers that can be used to address this challenge. \n",
      "The [Multi-Vector](/docs/how_to/multi_vector/) retriever allows the user to use any document transformation (e.g., use an LLM to write a summary of the document) for indexing while retaining linkage to the source document. \n",
      "The [ParentDocument](/docs/how_to/parent_document_retriever/) retriever links document chunks from a text-splitter transformation for indexing while retaining linkage to the source document. \n",
      "\n",
      "| Name                                                      | Index Type                    | Uses an LLM               | When to Use                                                                                                                             | Description                                                                                                                                                                                                              |\n",
      "|-----------------------------------------------------------|-------------------------------|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| [ParentDocument](/docs/how_to/parent_document_retriever/) | Vector store + Document Store | No                        | If your pages have lots of smaller pieces of distinct information that are best indexed by themselves, but best retrieved all together. | This involves indexing multiple chunks for each document. Then you find the chunks that are most similar in embedding space, but you retrieve the whole parent document and return that (rather than individual chunks). |\n",
      "| [Multi Vector](/docs/how_to/multi_vector/)                | Vector store + Document Store | Sometimes during indexing | If you are able to extract information from documents that you think is more relevant to index than the text itself.                    | This involves creating multiple vectors for each document. Each vector could be created in a myriad of ways - examples include summaries of the text and hypothetical questions.                                         |\n",
      "\n",
      ":::info[Further reading]\n",
      "\n",
      "* See our [how-to guide](/docs/how_to/parent_document_retriever/) on using the ParentDocument retriever.\n",
      "* See our [how-to guide](/docs/how_to/multi_vector/) on using the MultiVector retriever.\n",
      "* See our RAG from Scratch video on the [multi vector retriever](https://youtu.be/gTCU9I6QqCE?feature=shared).\n",
      "\n",
      ":::\n",
      "****************************************************************************************************\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "LangChain's retriever class -> REQUIRES_IMPLEMENTATION_OF -> _get_relevant_documents method\n",
      "\n",
      "## Interface \n",
      "\n",
      "The only requirement for a retriever is the ability to accepts a query and return documents. \n",
      "In particular, [LangChain's retriever class](https://python.langchain.com/api_reference/core/retrievers/langchain_core.retrievers.BaseRetriever.html#) only requires that the `_get_relevant_documents` method is implemented, which takes a `query: str` and returns a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects that are most relevant to the query.\n",
      "The underlying logic used to get relevant documents is specified by the retriever and can be whatever is most useful for the application.\n",
      "\n",
      "A LangChain retriever is a [runnable](/docs/how_to/lcel_cheatsheet/), which is a standard interface is for LangChain components. \n",
      "This means that it has a few common methods, including `invoke`, that are used to interact with it. A retriever can be invoked with a query:\n",
      "\n",
      "```python\n",
      "docs = retriever.invoke(query)\n",
      "```\n",
      "\n",
      "Retrievers return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects, which have two attributes:\n",
      "\n",
      "* `page_content`: The content of this document. Currently is a string.\n",
      "* `metadata`: Arbitrary metadata associated with this document (e.g., document id, file name, source, etc). \n",
      "\n",
      ":::info[Further reading]\n",
      "\n",
      "* See our [how-to guide](/docs/how_to/custom_retriever/) on building your own custom retriever.\n",
      "\n",
      ":::\n",
      "****************************************************************************************************\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "documents -> TYPE_OF -> LangChain Document\n",
      "\n",
      "## Overview\n",
      "\n",
      "Many different types of retrieval systems exist, including vectorstores, graph databases, and relational databases.\n",
      "With the rise on popularity of large language models, retrieval systems have become an important component in AI application (e.g., [RAG](/docs/concepts/rag/)).\n",
      "Because of their importance and variability, LangChain provides a uniform interface for interacting with different types of retrieval systems.\n",
      "The LangChain [retriever](/docs/concepts/retrievers/) interface is straightforward:\n",
      "\n",
      "1. Input: A query (string)\n",
      "2. Output: A list of documents (standardized LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects)\n",
      "****************************************************************************************************\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "search APIs -> RETURN -> search results\n",
      "Amazon Kendra -> IS_A -> retriever integration\n",
      "Wikipedia Search -> IS_A -> retriever integration\n",
      "\n",
      "### Search apis\n",
      "\n",
      "It's important to note that retrievers don't need to actually *store* documents. \n",
      "For example, we can be built retrievers on top of search APIs that simply return search results! \n",
      "See our retriever integrations with [Amazon Kendra](/docs/integrations/retrievers/amazon_kendra_retriever/) or [Wikipedia Search](/docs/integrations/retrievers/wikipedia/).\n",
      "****************************************************************************************************\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "BM25 -> INTEGRATION -> retriever integration\n",
      "Elasticsearch -> INTEGRATION -> retriever integration\n",
      "\n",
      "### Lexical search\n",
      "\n",
      "As discussed in our conceptual review of [retrieval](/docs/concepts/retrieval/), many search engines are based upon matching words in a query to the words in each document. \n",
      "[BM25](https://en.wikipedia.org/wiki/Okapi_BM25#:~:text=BM25%20is%20a%20bag%2Dof,slightly%20different%20components%20and%20parameters.) and [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) are [two popular lexical search algorithms](https://cameronrwolfe.substack.com/p/the-basics-of-ai-powered-vector-search?utm_source=profile&utm_medium=reader2).\n",
      "LangChain has retrievers for many popular lexical search algorithms / engines.\n",
      "\n",
      ":::info[Further reading]\n",
      "\n",
      "* See the [BM25](/docs/integrations/retrievers/bm25/) retriever integration.\n",
      "* See the [TF-IDF](/docs/integrations/retrievers/tf_idf/) retriever integration.\n",
      "* See the [Elasticsearch](/docs/integrations/retrievers/elasticsearch_retriever/) retriever integration.\n",
      "\n",
      ":::\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for record in results:\n",
    "    print(record.text)\n",
    "    print('*'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = gindex.as_query_engine(llm = llm, include_text=True)#, response_synthesizer=response_synthesizer)\n",
    "# query_engine = gindex.as_query_engine(\n",
    "#     include_text=False, response_mode=\"tree_summarize\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not langfuse_available:\n",
    "    response = query_engine.query(queries[1])\n",
    "else:\n",
    "    with langfuse.start_as_current_span(name=\"query gindex\"):\n",
    "        response = query_engine.query(queries[1])\n",
    "    langfuse.flush()\n",
    "\n",
    "# if langfuse_available:\n",
    "#     instrumentor.start()\n",
    "#     with instrumentor.observe(trace_name=\"query gindex\", user_id=\"sparsh\") as abc:\n",
    "#         response = query_engine.query(queries[1])\n",
    "#     instrumentor.flush()\n",
    "#     instrumentor.stop()\n",
    "# else:\n",
    "#     print('langfuse not setup')\n",
    "#     response = query_engine.query(queries[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain supports various types of retrievers, including those built on:\n",
      "\n",
      "*   **Lexical search algorithms/engines:** Such as BM25, TF-IDF, and Elasticsearch.\n",
      "*   **Search APIs:** Examples include integrations with Amazon Kendra and Wikipedia Search.\n",
      "\n",
      "The framework also provides a uniform interface for interacting with different retrieval systems like vectorstores, graph databases, and relational databases.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: e507fe1c-4f7f-40e6-b32b-29b01fe2309d): Here are some facts extracted from the provided text:\n",
      "\n",
      "LangChain's retriever class -> REQUIRES_IM...\n",
      "\n",
      "> Source (Doc id: cca2bfa1-311e-46ac-b7b8-00a986d86a91): Here are some facts extracted from the provided text:\n",
      "\n",
      "documents -> TYPE_OF -> LangChain Document...\n",
      "\n",
      "> Source (Doc id: eb622ec4-e081-4d53-8911-ec764ff8daf4): Here are some facts extracted from the provided text:\n",
      "\n",
      "search APIs -> RETURN -> search results\n",
      "Am...\n",
      "\n",
      "> Source (Doc id: dc0595ab-2a91-4804-a5ee-a8696ce45eeb): Here are some facts extracted from the provided text:\n",
      "\n",
      "BM25 -> INTEGRATION -> retriever integrati...\n"
     ]
    }
   ],
   "source": [
    "print(response.get_formatted_sources())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.property_graph import LLMSynonymRetriever\n",
    "from llama_index.core.indices.property_graph import VectorContextRetriever\n",
    "from llama_index.core.retrievers import TextToCypherRetriever\n",
    "from llama_index.core.indices.property_graph import CypherTemplateRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cypher(cypher):\n",
    "    print(str(cypher))\n",
    "    return cypher\n",
    "\n",
    "t2c_retriever = TextToCypherRetriever(\n",
    "    graph_store=graph_store,\n",
    "    llm=llm,\n",
    "    include_text=True,\n",
    "    # cypher_validator=validate_cypher,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not langfuse_available:\n",
    "     res = t2c_retriever.retrieve(queries[1])\n",
    "else:\n",
    "    with langfuse.start_as_current_span(name=\"text to cypher retreive\"):\n",
    "         res = t2c_retriever.retrieve(queries[1])\n",
    "    langfuse.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='9e7f05cc-9040-47aa-8d5f-5d086d52eae0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Generated Cypher query:\\nMATCH (f:FRAMEWORK {name: \"langchain\"})-[:HAS]->(r:RETRIEVER)\\nRETURN r.name AS retriever_type\\n\\nCypher Response:\\n[]', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = VectorContextRetriever(\n",
    "    graph_store=graph_store,\n",
    "    llm=llm,\n",
    "    include_text=False,\n",
    "    include_properties=False,\n",
    "    embed_model=embed_model,\n",
    "    similarity_top_k=20,\n",
    "    limit=30,\n",
    "    path_depth=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are the different types of retreivers supported by langchain?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = queries[1]\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not langfuse_available:\n",
    "     retrieved_nodes = vector_retriever.retrieve(query)\n",
    "else:\n",
    "    with langfuse.start_as_current_span(name=\"vector context retreive\"):\n",
    "         retrieved_nodes = vector_retriever.retrieve(query)\n",
    "    langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='a92393df-9a75-49cc-8801-96fe071ac6b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e507fe1c-4f7f-40e6-b32b-29b01fe2309d', node_type=None, metadata={}, hash=None)}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"LangChain's retriever class -> REQUIRES_IMPLEMENTATION_OF -> _get_relevant_documents method\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8507366180419922),\n",
       " NodeWithScore(node=TextNode(id_='c2245a8a-7905-4c32-886b-6c493926250a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='cca2bfa1-311e-46ac-b7b8-00a986d86a91', node_type=None, metadata={}, hash=None)}, metadata_template='{key}: {value}', metadata_separator='\\n', text='documents -> TYPE_OF -> LangChain Document', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.847414493560791),\n",
       " NodeWithScore(node=TextNode(id_='0bd5c8c1-d45f-4161-ba2f-0e71532ef26f', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='eb622ec4-e081-4d53-8911-ec764ff8daf4', node_type=None, metadata={}, hash=None)}, metadata_template='{key}: {value}', metadata_separator='\\n', text='search APIs -> RETURN -> search results', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8463034629821777)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_nodes[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain's retriever class -> REQUIRES_IMPLEMENTATION_OF -> _get_relevant_documents method\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import (\n",
    "    BaseSynthesizer,\n",
    "    ResponseMode,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: what are the different types of retreivers supported by langchain?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('query:', query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not langfuse_available:\n",
    "    response = response_synthesizer.synthesize(query=query, nodes=retrieved_nodes)\n",
    "else:\n",
    "    with langfuse.start_as_current_span(name=\"response synthesizer\"):\n",
    "        response = response_synthesizer.synthesize(query=query, nodes=retrieved_nodes)\n",
    "    langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain supports various types of retrievers, including integrations such as Amazon Kendra, Wikipedia Search, BM25, and Elasticsearch. Additionally, retrievers can be built from vectorstores and through text-to-SQL conversion.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: a92393df-9a75-49cc-8801-96fe071ac6b0): LangChain's retriever class -> REQUIRES_IMPLEMENTATION_OF -> _get_relevant_documents method\n",
      "\n",
      "> Source (Doc id: c2245a8a-7905-4c32-886b-6c493926250a): documents -> TYPE_OF -> LangChain Document\n",
      "\n",
      "> Source (Doc id: 0bd5c8c1-d45f-4161-ba2f-0e71532ef26f): search APIs -> RETURN -> search results\n",
      "\n",
      "> Source (Doc id: 00b0ca2c-3a50-4cf3-b297-028df8c7be74): Amazon Kendra -> IS_A -> retriever integration\n",
      "\n",
      "> Source (Doc id: 69e96ade-d529-4af8-ac9c-deab7d8650a9): Wikipedia Search -> IS_A -> retriever integration\n",
      "\n",
      "> Source (Doc id: 35970c85-3764-47a8-8afc-5eb407d8e729): BM25 -> INTEGRATION -> retriever integration\n",
      "\n",
      "> Source (Doc id: 39f1f453-ae26-4a47-a339-2fa9bdbd79bf): Elasticsearch -> INTEGRATION -> retriever integration\n",
      "\n",
      "> Source (Doc id: db171c9c-5f12-423b-abfe-c86e5aa63f56): LangChain retriever -> IS_A -> runnable\n",
      "\n",
      "> Source (Doc id: be8848d8-1fa9-4c64-9a25-258e184521a7): text-to-SQL conversion -> USED_FOR -> build a retriever\n",
      "\n",
      "> Source (Doc id: bbf0476b-b830-4d6e-8dea-2d29842a5d31): vectorstore -> CALLS_METHOD -> as_retriever()\n",
      "\n",
      "> Source (Doc id: 4f1b3f15-971c-4568-9ec9-ca6cd1027e0b): Retrievers -> CAN_BE_BUILT_ON -> search APIs\n",
      "\n",
      "> Source (Doc id: 862b2156-1cc4-4d6c-a497-d8843d43c8d6): Retrievers -> TYPE_OF -> Common types\n",
      "\n",
      "> Source (Doc id: 541f9246-377d-4206-8f58-665c91004ad3): Retrieval -> REQUIRES -> Retrievers\n",
      "\n",
      "> Source (Doc id: fcb93304-95e0-4a6c-8ec3-b8f0f03e1545): Retrievers -> RETURN -> list of Document objects\n",
      "\n",
      "> Source (Doc id: 86e3dbb9-a708-40a6-9b1e-6874d2814444): Retrievers -> DO_NOT_NEED_TO -> store documents\n",
      "\n",
      "> Source (Doc id: a9a1ca12-cca7-460c-b0c3-0557b0293e47): Retrievers -> BUILT_ON -> graph databases\n",
      "\n",
      "> Source (Doc id: f1424c87-2ae7-41ae-8928-1aad6fb27be5): Retrievers -> BUILT_ON -> relational database\n",
      "\n",
      "> Source (Doc id: fe429593-ab49-4bdd-91e8-5c0b6c95d027): _get_relevant_documents method -> TAKES -> query: str\n",
      "\n",
      "> Source (Doc id: 9ebf77b6-2764-475a-9670-9c050148de93): _get_relevant_documents method -> RETURNS -> list of Document objects\n",
      "\n",
      "> Source (Doc id: fd946e22-2368-4232-a117-05128c622b7d): embedding model -> COMPRESS -> documents\n",
      "\n",
      "> Source (Doc id: 36533703-cb56-4ac8-ba90-1fd0ebf77f2b): BM25 -> IS_A -> lexical search algorithm\n",
      "\n",
      "> Source (Doc id: 39f7c7d4-fdcf-4187-a36e-6717ee9ae6fc): BM25 -> TYPE_OF -> lexical search algorithm\n",
      "\n",
      "> Source (Doc id: dbcb0516-8fe4-4227-8b3a-b47ab54b07ef): BM25 -> INTEGRATED_IN -> LangChain\n",
      "\n",
      "> Source (Doc id: 43060365-ca06-4e68-8137-b7caae94db5c): Elasticsearch -> INTEGRATED_IN -> LangChain\n",
      "\n",
      "> Source (Doc id: e38c3f92-d989-4137-9267-ff607202e48d): runnable -> HAS_METHOD -> invoke\n",
      "\n",
      "> Source (Doc id: 3da00a14-e8f7-4c34-a015-655d52c4b83c): text-to-SQL conversion -> BUILDS -> retriever\n",
      "\n",
      "> Source (Doc id: 79f009c8-c20a-4323-a8c5-623b5f686fff): vectorstore -> RETURNS -> retriever\n",
      "\n",
      "> Source (Doc id: 9b5eabb3-6949-4fa8-b7aa-65008d7d60ee): vectorstore -> IS_INSTANCE_OF -> MyVectorStore\n"
     ]
    }
   ],
   "source": [
    "print(response.get_formatted_sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeWithScore(node=TextNode(id_='a92393df-9a75-49cc-8801-96fe071ac6b0', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e507fe1c-4f7f-40e6-b32b-29b01fe2309d', node_type=None, metadata={}, hash=None)}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"LangChain's retriever class -> REQUIRES_IMPLEMENTATION_OF -> _get_relevant_documents method\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.8507366180419922)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j Cypher queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Find the node containing the specific text\n",
    "\n",
    "```bash\n",
    "// 1. Find the node containing the specific text\n",
    "MATCH (target_node)\n",
    "WHERE target_node.text CONTAINS \"This package contains third-party integrations that are maintained by the LangChain community.\" // Or target_node.description, target_node.name etc.\n",
    "\n",
    "// 2. Get its immediate neighbors and the relationships\n",
    "OPTIONAL MATCH (target_node)-[r]-(neighbor)\n",
    "\n",
    "// 3. Return the target node, the relationships, and the neighbors\n",
    "RETURN target_node, r, neighbor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Find Duplicate Nodes\n",
    "\n",
    "lost the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/', '/Chat models/'],\n",
       " ['LangChain Framework', 'LangChain framework'],\n",
       " ['LangChain Framework', 'LangChain framework'],\n",
       " ['appropriately lightweight', 'lightweight', 'lightweight dependencies'],\n",
       " ['all integrations', 'integrations', 'third-party integrations'],\n",
       " ['langchain package', 'package', 'packages'],\n",
       " ['all integrations', 'integrations', 'third-party integrations'],\n",
       " ['langchain package', 'package', 'packages'],\n",
       " ['appropriately lightweight', 'lightweight', 'lightweight dependencies'],\n",
       " ['all integrations', 'integrations', 'third-party integrations'],\n",
       " ['appropriately lightweight', 'lightweight', 'lightweight dependencies'],\n",
       " ['debug', 'test'],\n",
       " ['debug', 'test'],\n",
       " ['LangServe documentation', 'LangSmith documentation'],\n",
       " ['Asynchronous programming', 'asynchronous programming'],\n",
       " ['Asynchronous programming', 'asynchronous programming'],\n",
       " ['async methods', 'method'],\n",
       " ['async methods', 'method'],\n",
       " ['event loop', 'tasks on the event loop'],\n",
       " ['event loop', 'tasks on the event loop'],\n",
       " ['curio', 'trio'],\n",
       " ['RunnableConfig', 'RunnableConfig propagation'],\n",
       " ['Python 3.10', 'Python 3.11', 'Python 3.9'],\n",
       " ['Python 3.10', 'Python 3.11', 'Python 3.9'],\n",
       " ['Python 3.10', 'Python 3.11', 'Python 3.9'],\n",
       " ['RunnableConfig', 'RunnableConfig propagation'],\n",
       " ['IPython', 'IPython REPL'],\n",
       " ['IPython', 'IPython REPL'],\n",
       " ['`on_llm_end`', '`on_llm_error`'],\n",
       " ['LLM ends', 'LLM errors'],\n",
       " ['llm ends', 'llm errors'],\n",
       " ['`on_llm_end`', '`on_llm_error`'],\n",
       " ['Async callback handlers', 'Callback handlers', 'Sync callback handlers'],\n",
       " ['async', 'sync'],\n",
       " ['Async callback handlers', 'Callback handlers', 'Sync callback handlers'],\n",
       " ['AsyncCallbackHandler interface', 'BaseCallbackHandler interface'],\n",
       " ['Async callback handlers', 'Callback handlers', 'Sync callback handlers'],\n",
       " ['AsyncCallbackHandler interface', 'BaseCallbackHandler interface'],\n",
       " ['AsyncCallbackManager', 'CallbackManager'],\n",
       " ['AsyncCallbackManager', 'CallbackManager'],\n",
       " ['Request time callbacks', 'request time callbacks'],\n",
       " ['all children', 'any children'],\n",
       " ['all children', 'any children'],\n",
       " ['Request time callbacks', 'request time callbacks'],\n",
       " ['system message', 'tool message', 'user message'],\n",
       " ['Conversation', 'conversation', 'conversation structure'],\n",
       " ['system message', 'tool message', 'user message'],\n",
       " ['specific task', 'specific tasks'],\n",
       " ['specific task', 'specific tasks'],\n",
       " ['first message', 'last message'],\n",
       " ['first message', 'last message'],\n",
       " ['system message', 'tool message', 'user message'],\n",
       " ['Conversation', 'conversation', 'conversation structure'],\n",
       " ['long-term memory', 'short-term memory'],\n",
       " ['long-term memory', 'short-term memory'],\n",
       " ['BaseChatModel', 'BaseChatModel interface'],\n",
       " ['BaseChatModel', 'BaseChatModel interface'],\n",
       " ['BaseLLM', 'BaseLLM interface'],\n",
       " ['BaseLLM', 'BaseLLM interface'],\n",
       " ['processing data', 'processing text'],\n",
       " ['processing data', 'processing text'],\n",
       " ['audio', 'video'],\n",
       " ['audio', 'video'],\n",
       " ['multimodal inputs', 'multimodal outputs'],\n",
       " ['multimodal inputs', 'multimodal outputs'],\n",
       " ['context window', 'large context windows'],\n",
       " ['entire input', 'input', 'input sequence', 'meaning of the input'],\n",
       " ['context window', 'large context windows'],\n",
       " ['entire input', 'input', 'input sequence', 'meaning of the input'],\n",
       " ['entire input', 'input', 'input sequence', 'meaning of the input'],\n",
       " ['/', '/Chat models/'],\n",
       " ['Rate limit', 'Rate limits'],\n",
       " ['Rate limit error', 'rate limit error'],\n",
       " ['Spacing out requests', 'spacing out requests'],\n",
       " ['Rate limit error', 'rate limit error'],\n",
       " ['Chat model',\n",
       "  'ChatModel',\n",
       "  'all chat models',\n",
       "  'another chat model',\n",
       "  'chat model',\n",
       "  'different chat models'],\n",
       " ['Chat model',\n",
       "  'ChatModel',\n",
       "  'all chat models',\n",
       "  'another chat model',\n",
       "  'chat model',\n",
       "  'different chat models'],\n",
       " ['Rate limit', 'Rate limits'],\n",
       " ['Spacing out requests', 'spacing out requests'],\n",
       " ['Caching', 'Caching chat model responses'],\n",
       " ['Caching', 'Caching chat model responses'],\n",
       " ['entire input', 'input', 'input sequence', 'meaning of the input'],\n",
       " ['How-to guides', 'how-to guides'],\n",
       " ['Common retrieval systems', 'Retrieval systems', 'retrieval systems'],\n",
       " ['Embedding', 'embedding', 'embedding space'],\n",
       " ['BERT', 'BERT architecture', 'SBERT'],\n",
       " ['BERT', 'BERT architecture', 'SBERT'],\n",
       " ['BERT', 'BERT architecture', 'SBERT'],\n",
       " ['Cosine Similarity', 'cosine similarity'],\n",
       " ['Embedding', 'embedding', 'embedding space'],\n",
       " ['Embedding', 'embedding', 'embedding space'],\n",
       " ['Cosine Similarity', 'cosine similarity'],\n",
       " ['langchain package', 'package', 'packages'],\n",
       " ['LangServe documentation', 'LangSmith documentation'],\n",
       " ['Evaluation', 'evaluation'],\n",
       " ['Evaluation', 'evaluation'],\n",
       " ['Example selectors', 'example selectors'],\n",
       " ['Few-shot prompting', 'prompting'],\n",
       " ['Example selectors', 'example selectors'],\n",
       " ['LLM feedback', 'User feedback'],\n",
       " ['LLM feedback', 'User feedback'],\n",
       " ['latency', 'latency constraints'],\n",
       " ['latency', 'latency constraints'],\n",
       " ['keyword-based similarity', 'similarity'],\n",
       " ['keyword-based similarity', 'similarity'],\n",
       " ['AI application', 'AI applications', 'LLM applications'],\n",
       " ['API Reference', 'API reference', 'Document API reference'],\n",
       " ['BaseStore', 'BaseStore[str, bytes]', 'BaseStores'],\n",
       " ['BaseStore', 'BaseStore[str, bytes]', 'BaseStores'],\n",
       " ['BaseStore', 'BaseStore[str, bytes]', 'BaseStores'],\n",
       " ['mdelete', 'mget', 'mset'],\n",
       " ['mdelete', 'mget', 'mset'],\n",
       " ['mdelete', 'mget', 'mset'],\n",
       " ['key', 'key_value_pairs'],\n",
       " ['key', 'key_value_pairs'],\n",
       " ['LCEL chains', 'LLMChain'],\n",
       " ['final_output', 'output', 'output1'],\n",
       " ['runnable1', 'runnable2'],\n",
       " ['runnable1', 'runnable2'],\n",
       " ['runnable1.invoke', 'runnable2.invoke'],\n",
       " ['final_output', 'output', 'output1'],\n",
       " ['runnable1.invoke', 'runnable2.invoke'],\n",
       " ['final_output', 'output', 'output1'],\n",
       " ['asynchronous execution', 'synchronous execution'],\n",
       " ['asynchronous execution', 'synchronous execution'],\n",
       " ['`|` operator', '| operator'],\n",
       " ['`|` operator', '| operator'],\n",
       " ['automatic type coercion', 'type coercion'],\n",
       " ['automatic type coercion', 'type coercion'],\n",
       " ['LCEL chains', 'LLMChain'],\n",
       " ['Chat model',\n",
       "  'ChatModel',\n",
       "  'all chat models',\n",
       "  'another chat model',\n",
       "  'chat model',\n",
       "  'different chat models'],\n",
       " ['ID', 'Name'],\n",
       " ['ID', 'Name'],\n",
       " ['Name property', 'name property'],\n",
       " ['Name property', 'name property'],\n",
       " ['Conversation', 'conversation', 'conversation structure'],\n",
       " ['Chat model',\n",
       "  'ChatModel',\n",
       "  'all chat models',\n",
       "  'another chat model',\n",
       "  'chat model',\n",
       "  'different chat models'],\n",
       " ['system role', 'tool role', 'user role'],\n",
       " ['system role', 'tool role', 'user role'],\n",
       " ['system role', 'tool role', 'user role'],\n",
       " ['langchain_core.messages', 'langchain_core.messages.utils'],\n",
       " ['single string', 'string'],\n",
       " ['invalid_tool_calls', 'tool_calls'],\n",
       " ['image_url', 'type', 'url'],\n",
       " ['astream', 'astream_events'],\n",
       " ['astream', 'astream_events'],\n",
       " ['langchain_core.messages', 'langchain_core.messages.utils'],\n",
       " ['text, images, audio', 'text, images, audio, video'],\n",
       " ['text, images, audio', 'text, images, audio, video'],\n",
       " ['image_url', 'type', 'url'],\n",
       " ['image_url', 'type', 'url'],\n",
       " ['multimodal retrieval', 'retrieval', 'retrieval tasks'],\n",
       " ['multimodal retrieval', 'retrieval', 'retrieval tasks'],\n",
       " ['multimodal retrieval', 'retrieval', 'retrieval tasks'],\n",
       " ['CSV', 'Str'],\n",
       " ['Prompt Templates', 'prompt templates'],\n",
       " ['Chat model',\n",
       "  'ChatModel',\n",
       "  'all chat models',\n",
       "  'another chat model',\n",
       "  'chat model',\n",
       "  'different chat models'],\n",
       " ['single string', 'string'],\n",
       " ['Prompt Templates', 'prompt templates'],\n",
       " ['Retrievers', 'retrievers'],\n",
       " ['Common retrieval systems', 'Retrieval systems', 'retrieval systems'],\n",
       " ['Data',\n",
       "  'Structured data',\n",
       "  'Unstructured text',\n",
       "  'all types of data',\n",
       "  'unstructured data'],\n",
       " ['Relational databases', 'relational database', 'relational databases'],\n",
       " ['Graph databases', 'graph database', 'graph databases'],\n",
       " ['Data',\n",
       "  'Structured data',\n",
       "  'Unstructured text',\n",
       "  'all types of data',\n",
       "  'unstructured data'],\n",
       " ['Translation', 'translation'],\n",
       " ['Search queries', 'search query'],\n",
       " ['Translation', 'translation'],\n",
       " ['Text to SQL', 'Text-to-SQL', 'text-to-SQL', 'text-to-SQL conversion'],\n",
       " ['Natural Language', 'natural language to Cypher', 'natural language to SQL'],\n",
       " ['Text-to-Cypher', 'text-to-Cypher'],\n",
       " ['Natural Language', 'natural language to Cypher', 'natural language to SQL'],\n",
       " ['Metadata Filters', 'metadata filter'],\n",
       " ['Metadata Filters', 'metadata filter'],\n",
       " ['Text to SQL', 'Text-to-SQL', 'text-to-SQL', 'text-to-SQL conversion'],\n",
       " ['/Retrieval/', '/Retrieval/Information retrieval'],\n",
       " ['/Retrieval/', '/Retrieval/Information retrieval'],\n",
       " ['Common retrieval systems', 'Retrieval systems', 'retrieval systems'],\n",
       " ['index', 'inverted index'],\n",
       " ['Data',\n",
       "  'Structured data',\n",
       "  'Unstructured text',\n",
       "  'all types of data',\n",
       "  'unstructured data'],\n",
       " ['documents', 'list of documents', 'store documents'],\n",
       " ['Relational databases', 'relational database', 'relational databases'],\n",
       " ['data into tables', 'table', 'tables'],\n",
       " ['data into tables', 'table', 'tables'],\n",
       " ['data into tables', 'table', 'tables'],\n",
       " ['Data',\n",
       "  'Structured data',\n",
       "  'Unstructured text',\n",
       "  'all types of data',\n",
       "  'unstructured data'],\n",
       " ['Graph databases', 'graph database', 'graph databases'],\n",
       " ['documents', 'list of documents', 'store documents'],\n",
       " ['Document objects', 'list of Document objects'],\n",
       " ['query analysis', 'query analysis techniques'],\n",
       " ['Text to SQL', 'Text-to-SQL', 'text-to-SQL', 'text-to-SQL conversion'],\n",
       " ['Retrievers', 'retrievers'],\n",
       " ['Document objects', 'list of Document objects'],\n",
       " ['documents', 'list of documents', 'store documents'],\n",
       " ['Relational databases', 'relational database', 'relational databases'],\n",
       " ['Text to SQL', 'Text-to-SQL', 'text-to-SQL', 'text-to-SQL conversion'],\n",
       " ['Graph databases', 'graph database', 'graph databases'],\n",
       " ['Text-to-Cypher', 'text-to-Cypher'],\n",
       " ['Search queries', 'search query'],\n",
       " ['ParentDocument', 'ParentDocument retriever'],\n",
       " ['ParentDocument', 'ParentDocument retriever']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicates\n",
    "dup_ent = [[\"/\", \"/Chat models/\"], [\"LangChain Framework\", \"LangChain framework\"], [\"LangChain Framework\", \"LangChain framework\"], [\"appropriately lightweight\", \"lightweight\", \"lightweight dependencies\"], [\"all integrations\", \"integrations\", \"third-party integrations\"], [\"langchain package\", \"package\", \"packages\"], [\"all integrations\", \"integrations\", \"third-party integrations\"], [\"langchain package\", \"package\", \"packages\"], [\"appropriately lightweight\", \"lightweight\", \"lightweight dependencies\"], [\"all integrations\", \"integrations\", \"third-party integrations\"], [\"appropriately lightweight\", \"lightweight\", \"lightweight dependencies\"], [\"debug\", \"test\"], [\"debug\", \"test\"], [\"LangServe documentation\", \"LangSmith documentation\"], [\"Asynchronous programming\", \"asynchronous programming\"], [\"Asynchronous programming\", \"asynchronous programming\"], [\"async methods\", \"method\"], [\"async methods\", \"method\"], [\"event loop\", \"tasks on the event loop\"], [\"event loop\", \"tasks on the event loop\"], [\"curio\", \"trio\"], [\"RunnableConfig\", \"RunnableConfig propagation\"], [\"Python 3.10\", \"Python 3.11\", \"Python 3.9\"], [\"Python 3.10\", \"Python 3.11\", \"Python 3.9\"], [\"Python 3.10\", \"Python 3.11\", \"Python 3.9\"], [\"RunnableConfig\", \"RunnableConfig propagation\"], [\"IPython\", \"IPython REPL\"], [\"IPython\", \"IPython REPL\"], [\"`on_llm_end`\", \"`on_llm_error`\"], [\"LLM ends\", \"LLM errors\"], [\"llm ends\", \"llm errors\"], [\"`on_llm_end`\", \"`on_llm_error`\"], [\"Async callback handlers\", \"Callback handlers\", \"Sync callback handlers\"], [\"async\", \"sync\"], [\"Async callback handlers\", \"Callback handlers\", \"Sync callback handlers\"], [\"AsyncCallbackHandler interface\", \"BaseCallbackHandler interface\"], [\"Async callback handlers\", \"Callback handlers\", \"Sync callback handlers\"], [\"AsyncCallbackHandler interface\", \"BaseCallbackHandler interface\"], [\"AsyncCallbackManager\", \"CallbackManager\"], [\"AsyncCallbackManager\", \"CallbackManager\"], [\"Request time callbacks\", \"request time callbacks\"], [\"all children\", \"any children\"], [\"all children\", \"any children\"], [\"Request time callbacks\", \"request time callbacks\"], [\"system message\", \"tool message\", \"user message\"], [\"Conversation\", \"conversation\", \"conversation structure\"], [\"system message\", \"tool message\", \"user message\"], [\"specific task\", \"specific tasks\"], [\"specific task\", \"specific tasks\"], [\"first message\", \"last message\"], [\"first message\", \"last message\"], [\"system message\", \"tool message\", \"user message\"], [\"Conversation\", \"conversation\", \"conversation structure\"], [\"long-term memory\", \"short-term memory\"], [\"long-term memory\", \"short-term memory\"], [\"BaseChatModel\", \"BaseChatModel interface\"], [\"BaseChatModel\", \"BaseChatModel interface\"], [\"BaseLLM\", \"BaseLLM interface\"], [\"BaseLLM\", \"BaseLLM interface\"], [\"processing data\", \"processing text\"], [\"processing data\", \"processing text\"], [\"audio\", \"video\"], [\"audio\", \"video\"], [\"multimodal inputs\", \"multimodal outputs\"], [\"multimodal inputs\", \"multimodal outputs\"], [\"context window\", \"large context windows\"], [\"entire input\", \"input\", \"input sequence\", \"meaning of the input\"], [\"context window\", \"large context windows\"], [\"entire input\", \"input\", \"input sequence\", \"meaning of the input\"], [\"entire input\", \"input\", \"input sequence\", \"meaning of the input\"], [\"/\", \"/Chat models/\"], [\"Rate limit\", \"Rate limits\"], [\"Rate limit error\", \"rate limit error\"], [\"Spacing out requests\", \"spacing out requests\"], [\"Rate limit error\", \"rate limit error\"], [\"Chat model\", \"ChatModel\", \"all chat models\", \"another chat model\", \"chat model\", \"different chat models\"], [\"Chat model\", \"ChatModel\", \"all chat models\", \"another chat model\", \"chat model\", \"different chat models\"], [\"Rate limit\", \"Rate limits\"], [\"Spacing out requests\", \"spacing out requests\"], [\"Caching\", \"Caching chat model responses\"], [\"Caching\", \"Caching chat model responses\"], [\"entire input\", \"input\", \"input sequence\", \"meaning of the input\"], [\"How-to guides\", \"how-to guides\"], [\"Common retrieval systems\", \"Retrieval systems\", \"retrieval systems\"], [\"Embedding\", \"embedding\", \"embedding space\"], [\"BERT\", \"BERT architecture\", \"SBERT\"], [\"BERT\", \"BERT architecture\", \"SBERT\"], [\"BERT\", \"BERT architecture\", \"SBERT\"], [\"Cosine Similarity\", \"cosine similarity\"], [\"Embedding\", \"embedding\", \"embedding space\"], [\"Embedding\", \"embedding\", \"embedding space\"], [\"Cosine Similarity\", \"cosine similarity\"], [\"langchain package\", \"package\", \"packages\"], [\"LangServe documentation\", \"LangSmith documentation\"], [\"Evaluation\", \"evaluation\"], [\"Evaluation\", \"evaluation\"], [\"Example selectors\", \"example selectors\"], [\"Few-shot prompting\", \"prompting\"], [\"Example selectors\", \"example selectors\"], [\"LLM feedback\", \"User feedback\"], [\"LLM feedback\", \"User feedback\"], [\"latency\", \"latency constraints\"], [\"latency\", \"latency constraints\"], [\"keyword-based similarity\", \"similarity\"], [\"keyword-based similarity\", \"similarity\"], [\"AI application\", \"AI applications\", \"LLM applications\"], [\"API Reference\", \"API reference\", \"Document API reference\"], [\"BaseStore\", \"BaseStore[str, bytes]\", \"BaseStores\"], [\"BaseStore\", \"BaseStore[str, bytes]\", \"BaseStores\"], [\"BaseStore\", \"BaseStore[str, bytes]\", \"BaseStores\"], [\"mdelete\", \"mget\", \"mset\"], [\"mdelete\", \"mget\", \"mset\"], [\"mdelete\", \"mget\", \"mset\"], [\"key\", \"key_value_pairs\"], [\"key\", \"key_value_pairs\"], [\"LCEL chains\", \"LLMChain\"], [\"final_output\", \"output\", \"output1\"], [\"runnable1\", \"runnable2\"], [\"runnable1\", \"runnable2\"], [\"runnable1.invoke\", \"runnable2.invoke\"], [\"final_output\", \"output\", \"output1\"], [\"runnable1.invoke\", \"runnable2.invoke\"], [\"final_output\", \"output\", \"output1\"], [\"asynchronous execution\", \"synchronous execution\"], [\"asynchronous execution\", \"synchronous execution\"], [\"`|` operator\", \"| operator\"], [\"`|` operator\", \"| operator\"], [\"automatic type coercion\", \"type coercion\"], [\"automatic type coercion\", \"type coercion\"], [\"LCEL chains\", \"LLMChain\"], [\"Chat model\", \"ChatModel\", \"all chat models\", \"another chat model\", \"chat model\", \"different chat models\"], [\"ID\", \"Name\"], [\"ID\", \"Name\"], [\"Name property\", \"name property\"], [\"Name property\", \"name property\"], [\"Conversation\", \"conversation\", \"conversation structure\"], [\"Chat model\", \"ChatModel\", \"all chat models\", \"another chat model\", \"chat model\", \"different chat models\"], [\"system role\", \"tool role\", \"user role\"], [\"system role\", \"tool role\", \"user role\"], [\"system role\", \"tool role\", \"user role\"], [\"langchain_core.messages\", \"langchain_core.messages.utils\"], [\"single string\", \"string\"], [\"invalid_tool_calls\", \"tool_calls\"], [\"image_url\", \"type\", \"url\"], [\"astream\", \"astream_events\"], [\"astream\", \"astream_events\"], [\"langchain_core.messages\", \"langchain_core.messages.utils\"], [\"text, images, audio\", \"text, images, audio, video\"], [\"text, images, audio\", \"text, images, audio, video\"], [\"image_url\", \"type\", \"url\"], [\"image_url\", \"type\", \"url\"], [\"multimodal retrieval\", \"retrieval\", \"retrieval tasks\"], [\"multimodal retrieval\", \"retrieval\", \"retrieval tasks\"], [\"multimodal retrieval\", \"retrieval\", \"retrieval tasks\"], [\"CSV\", \"Str\"], [\"Prompt Templates\", \"prompt templates\"], [\"Chat model\", \"ChatModel\", \"all chat models\", \"another chat model\", \"chat model\", \"different chat models\"], [\"single string\", \"string\"], [\"Prompt Templates\", \"prompt templates\"], [\"Retrievers\", \"retrievers\"], [\"Common retrieval systems\", \"Retrieval systems\", \"retrieval systems\"], [\"Data\", \"Structured data\", \"Unstructured text\", \"all types of data\", \"unstructured data\"], [\"Relational databases\", \"relational database\", \"relational databases\"], [\"Graph databases\", \"graph database\", \"graph databases\"], [\"Data\", \"Structured data\", \"Unstructured text\", \"all types of data\", \"unstructured data\"], [\"Translation\", \"translation\"], [\"Search queries\", \"search query\"], [\"Translation\", \"translation\"], [\"Text to SQL\", \"Text-to-SQL\", \"text-to-SQL\", \"text-to-SQL conversion\"], [\"Natural Language\", \"natural language to Cypher\", \"natural language to SQL\"], [\"Text-to-Cypher\", \"text-to-Cypher\"], [\"Natural Language\", \"natural language to Cypher\", \"natural language to SQL\"], [\"Metadata Filters\", \"metadata filter\"], [\"Metadata Filters\", \"metadata filter\"], [\"Text to SQL\", \"Text-to-SQL\", \"text-to-SQL\", \"text-to-SQL conversion\"], [\"/Retrieval/\", \"/Retrieval/Information retrieval\"], [\"/Retrieval/\", \"/Retrieval/Information retrieval\"], [\"Common retrieval systems\", \"Retrieval systems\", \"retrieval systems\"], [\"index\", \"inverted index\"], [\"Data\", \"Structured data\", \"Unstructured text\", \"all types of data\", \"unstructured data\"], [\"documents\", \"list of documents\", \"store documents\"], [\"Relational databases\", \"relational database\", \"relational databases\"], [\"data into tables\", \"table\", \"tables\"], [\"data into tables\", \"table\", \"tables\"], [\"data into tables\", \"table\", \"tables\"], [\"Data\", \"Structured data\", \"Unstructured text\", \"all types of data\", \"unstructured data\"], [\"Graph databases\", \"graph database\", \"graph databases\"], [\"documents\", \"list of documents\", \"store documents\"], [\"Document objects\", \"list of Document objects\"], [\"query analysis\", \"query analysis techniques\"], [\"Text to SQL\", \"Text-to-SQL\", \"text-to-SQL\", \"text-to-SQL conversion\"], [\"Retrievers\", \"retrievers\"], [\"Document objects\", \"list of Document objects\"], [\"documents\", \"list of documents\", \"store documents\"], [\"Relational databases\", \"relational database\", \"relational databases\"], [\"Text to SQL\", \"Text-to-SQL\", \"text-to-SQL\", \"text-to-SQL conversion\"], [\"Graph databases\", \"graph database\", \"graph databases\"], [\"Text-to-Cypher\", \"text-to-Cypher\"], [\"Search queries\", \"search query\"], [\"ParentDocument\", \"ParentDocument retriever\"], [\"ParentDocument\", \"ParentDocument retriever\"]]\n",
    "dup_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
